---
title: "BIOL 497/597 - Genomics & Bioinformatics"
subtitle: "Chapters"
author: "Sven Buerki - Boise State University"
date: "`r Sys.Date()`"
output:
  bookdown::html_document2: 
    toc: TRUE
    toc_float: TRUE
    toc_depth: 4
link-citations: yes
fontsize: 12pt
urlcolor: blue
csl: AmJBot.csl
bibliography: References.bib
editor_options: 
  markdown: 
    wrap: sentence
---

```{js logo-js, echo=FALSE}
$(document).ready(function() {
  $('#header').parent().prepend('<div id=\"logo\"><img src=\"Images/boisestate-primarylogo-2color-rgb.png\" style=\"position:absolute; top:0; right:0; padding:10px; height:120px\"></div>');
  $('#header').css('margin-right', '120px')
});
```

# Chapter 4

## Objectives

In this chapter, we aim at training students in producing a draft nuclear genome for a non-model organism using Illumina data.

The whole-genome shotgun (WGS) sequencing dataset published by @Zhang2017 on the orchid species *Apostasia shenzhenica* is used as case-study. This dataset provides an opportunity to gain firsthand experience in analyzing NGS data. @Zhang2017 have also produced RNA-Seq data, which were used in their study to support genome annotation.

The chapter is subdivided into three parts:

- **PART 1:** Preparing/cleaning Illumina reads for *de novo* nuclear genome assembly and inferring genome size and complexity.
- **PART 2:** *De novo* genome assembly.
- **PART 3:** Validation of draft genome. 

Before you start working on Chapter 4, please make sure that you have completed the tutorials available [here](Tutorials.html).

## Presenting the NGS data

Details on the WGS PE Illumina library studied here are provided in Figure \@ref(fig:SRA). The SRA accession number is [SRR5759389](https://trace.ncbi.nlm.nih.gov/Traces/sra/?run=SRR5759389) and the most important information to know about this data are that the fragments insert-size of the library is 180 bp and that the length of each PE read is 90 bp. Note that the authors have performed a round of PCR amplification during their library preparation. This step is know to potentially introduce errors in reads, which could be identified by performing k-mer analyses.

The number of bases shown in Figure \@ref(fig:SRA) was inferred as follows: $\text{N bases} = \text{N. spots * reads length (bp)}$. In this example, $\text{N bases} = 84.1e6 * 180 (90 + 90) = 15.1e9bp = 15.1Gbp$. 

You can also obtain a rough estimate of haploid genome coverage (x) by using the following equation: $\text{Raw haploid genome coverage (x)} = \text{N bases / Genome size (haploid)}$. In this example, $\text{Raw haploid genome coverage (x)} = 15.1e9 / 471.0e6 = 32x$. The estimation of haploid genome size was taken from @Zhang2017.

```{r SRA, echo=FALSE, fig.align="center", fig.cap="Details on the WGS library (SRA accession number: SRR5759389) used in this tutorial. ", fig.show="asis", out.width = '100%'}
knitr::include_graphics("Images/SRR5759389_details.png")
```

## Write your own scripts

As you go along this document and perform analyses, please COPY ALL COMMAND LINES into an `.Rmd` document saved in a folder entitled `Report/` (create this folder in your working directory; see below). Remember to comment your script (using \#s). This will greatly help you in repeating your analyses or using parts of your code to create new scripts. Enjoy scripting!

## PART 1

### Analytical workflow

The overarching objective of this tutorial is to gain theoretical and bioinformatics knowledge on the steps required to prepare PE Illumina reads for *de novo* nuclear genome assembly as well as infer genome size and complexity (see Figure \@ref(fig:part1)).

```{r part1, echo=FALSE, fig.align="center", fig.cap="Workflow applied to assemble and annotate a genome for non-model organisms. Steps associated to PART 1 are highlighted in grey.", fig.show="asis", out.width = '80%'}
knitr::include_graphics("Images/Chapter_4_Part1_steps_covered.png")
```

The five main steps associated to the objectives of PART 1 are as follows (see Figure \@ref(fig:part1workflow)):  

- **Step 1:** Download SRA file containing raw WGS data and simultaneously convert it into an interleaved PE `fasqt` format file. This latter format (where both reads are paired and combined into one file) is the input for most bioinformatic programs.
- **Step 2:** Infer reads Quality Checks (QCs) using standard statistics implemented in `FastQC` [@FastQC].
- **Step 3:** Perform reads cleaning based on Phread scores and k-mer frequencies.
- **Step 4:** What's "in" the reads? This will be done in two phases as follows:
    - Infer and plot clean reads GC contents to assess potential contamination patterns.
    - Map clean reads against reference genomes to assess the proportions of reads belonging to either nuclear or chloroplast genomes.
- **Step 5:** Estimate genome size and complexity (especially looking at repetitive elements and heterozygosity rate) using k-mer frequencies.

```{r part1workflow, echo=FALSE, fig.align="center", fig.cap="Overview of the analytical workflow applied here to prepare/clean Illumina reads for genome assembly and inferring genome size and complexity. Details on associated bioinformatic tools (here software) and file formats are also provided.", fig.show="asis", out.width = '100%'}
knitr::include_graphics("Images/Cleaning_reads.png")
```

### Location of the data on Linux computers

A folder entitled `Kmers_analyses/` (deposited onto your `bioinformatics` sessions) is located in `Documents/` and contains all the required files and programs to conduct the analyses. The instructor encourages you to explore the content of this folder using the UNIX command `ls -al`. Within each folder associated with each major step of this tutorial, there is a folder entitled `output/` containing the output files of the analyses. This is a back-up plan in case you have some troubles with the analyses or are running out of time. Finally, in the tutorial, the instructor will only refer to the name of the folder containing information about the analyses and not provide their full paths. 

### Bioinformatic tools

Although all the bioinformatic tools (software) necessary to complete this tutorial are already installed on your Linux computers, URLs to their repositories (incl. documentations) are provided below together with details on their publications (when available). Software are sorted by steps in our analytical workflow (see Figure \@ref(fig:part1workflow)):

- **Step 1:** `fastq-dump`: https://www.ncbi.nlm.nih.gov/sra/docs/toolkitsoft/.
- **Step 2:** `FastQC` [@FastQC]: https://www.bioinformatics.babraham.ac.uk/projects/fastqc/.
- **Step 3:** 
    - `seqtk`: https://github.com/lh3/seqtk.
    - `khmer` [@khmer2015]: https://github.com/dib-lab/khmer.
- **Step 4:**
    - `bwa` [@bwa2009]: http://bio-bwa.sourceforge.net.
    - `samtools`[@samtools2009]: http://samtools.sourceforge.net.
- **Step 5:** 
    - `jellyfish` [@Jellyfish2011]: http://www.genome.umd.edu/jellyfish.html.
    - `GenomeScope` [@genomescope]: http://qb.cshl.edu/genomescope/.

The `R` software is also used in steps 4 and 5. You can find more details on this software in the [Syllabus](index.html) and [Mini-Report](Mini_reports.html) webpages.

### Step 1: Download SRA file

The SRA format (containing raw NGS data) can be quite difficult to play with. Here, we aim at downloading the WGS data, split PE reads, but store both reads (R1 and R2) in the same file using the interleaved format (Figure \@ref(fig:part1workflow)). This format is very convenient and is the entry point for most reads cleaning programs. This task can be done by using `fastq-dump` from the [SRA Toolkit](https://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?view=software).

Before starting, open a Terminal and navigate to the `SRA/` folder using the `cd` command. Once there, execute the following command:

```{bash eval = F}
#Download PE reads (properly edited) in interleave format using SRA Toolkit
fastq-dump --split-files --defline-seq '@$ac.$si.$sg/$ri' --defline-qual '+' -Z SRR5759389 	> SRR5759389_pe12.fastq
```

Downloading the file can take a while!

### Step 2: Reads QCs {#Step2}

The program `FastQC` is used to obtain preliminary information about the Illumina library (see Figure \@ref(fig:SRA)). To run this program navigate to the `FastQC/` folder uisng `cd` and execute the following command:

```{bash eval = F}
#Reads QCs with FastQC 
./fastqc -o ~/Documents/Kmers_analyses/FastQC/ ~/Documents/Kmers_analyses/SRA/SRR5759389_pe12.fastq
```

Please inspect the `SRR5759389_pe12_fastqc.html` output file. We will have a group discussion to inspect this file and draw general conclusions on the quality of the raw data. This step will have to be repeated after completion of the step3 (reads cleaning) to confirm that our reads trimming and cleaning procedure was successful. 

### Step 3: Reads cleaning {#Step3}

This step is at the core of our analytical workflow. It is paramount to conduct thorough reads cleaning when assembling a nuclear genome due to the very nature of this genome (i.e. repetitive elements, heterozygosity, recombination, etc...). In this case, aim at minimizing the effect of PCR errors, which could jeopardize our assembly by creating false polymorphism. In addition, *de novo* genome assembly is computing intensive and by properly cleaning reads we will dramatically decrease RAM requirements.

#### Approach applied here to clean reads

Reads will be cleaned/trimmed based on (see Figure \@ref(fig:part1workflow)):

- Phred quality scores (33) to conduct a first round of trimming.
- K-mer frequencies (k=21) to:
    - Normalize high coverage reads (higher than 100x) based on median reads coverage.
    - Filter low abundance reads (where PCR errors will most likely take place).
- A final round of cleaning by removing low quality bases, short sequences, and non-paired reads.

Finally, we will format the clean data for *de novo* genome assembly, which will be conducted using `SOAPdenovo2` [@Luo2012].

#### What is a k-mer?

A `k-mer` is a substring of length $k$ in a string of DNA bases. For a given sequence of length $L$,  and a k-mer size of $k$, the total k-mer’s possible ($n$) will be given by $(L-k) + 1$. For instance, in a sequence of length of 9 ($L$), and a k-mer length of 2 ($k$), the number of k-mer’s generated will be: $n = (9-2) + 1 = 8$.

> All eight 2-mers of the sequence "AATTGGCCG" are:
> AA, AT, TT, TG, GG, GC, CC, CG

In most studies, the authors provide an estimate of sequencing coverage prior to assembly [e.g. 73 fold in the case of the giant panda genome, @Li2009], but the real coverage distribution will be influenced by factors including DNA quality, library preparation and local GC content. On average, you might expect most of the genome (especially the single/low copy genes) to be covered between 20 and 70x. One way of rapidly examining the coverage distribution before assembling a reference genome is to chop your cleaned sequence reads into short "k-mers" of 21 nucleotides, and count how often you get each possible k-mer. By doing so, you will find out that:

- Many sequences are extremely rare (e.g., once). These are likely to be PCR errors that appeared during library preparation or sequencing, or could be rare somatic mutations). Such sequences can confuse assembly software; eliminating them can decrease subsequent memory and CPU requirements.
- Other sequences may exist at 10,000x coverage. These could be pathogens or repetitive elements. Often, there is no benefit to retaining all copies of such sequences because the assembly software will be confused by them; while retaining a small proportion such reads could significantly reduce CPU, memory and space requirements.

Please find below the plot of k-mer frequencies inferred from the trimmed library studied here (`SRR5759389`), which suggests that the haploid genome of *Apostasia shenzhenica* is sequenced at ca. 25x (Figure \@ref(fig:kmerstrimmed)). The methodology used to infer this graph is explained in Step 4.

```{r kmerstrimmed, echo=FALSE, fig.align="center", fig.cap="Distribution of 21-mer frequencies based on the trimmed library with insert fragment size of 180 bp. Given only one peak in the k-mer distribution, we predict that the *Apostasia shenzhenica* genome has limited heterozygosity or in other words, that this genome is inbred.", fig.show="asis", out.width = '100%'}
knitr::include_graphics("Images/GenomeSize_trimmed.png")
```

#### K-mer graph and PCR effect

The peak around 25 in Figure \@ref(fig:kmerstrimmed) is the coverage with the highest number of different 21-mers. This means that there are $1.4e^7$ unique 21-mers (frequency) that have been observed 25 times (coverage). The normal-like distribution is due to the fact that the sequencing did not provide a perfect coverage of the whole genome. Some regions have less coverage, whereas others have a little more coverage, but the average coverage depth is around 25.

The large number of unique k-mers ($1.7e^7$) that have a frequency of 1 (right left side of the graph; Figure \@ref(fig:kmerstrimmed)) is most likely due to PCR errors. Please find below an example explaining how PCR errors impact on the k-mer procedure.

All 3-mers of the sequence "AATTGGCCG" are:

- AAT, ATT, TTG, TGG, GGC, GCC, CCG


Now, let's consider that the 4th letter (`T`) in the sequence above is replaced with a `C` to simulate a PCR error. In this context, all 3-mers of this sequence "AAT**C**GGCCG" are:

- AAT, **ATC**, **TCG**, **CGG**, GGC, GCC, CCG. 

The k-mers in bold are the incorrect 3-mers that are now unique and end up at the beginning of the graph in Figure \@ref(fig:kmerstrimmed).

Overall, the **general rule** is that for a given sequence, **a single PCR error will result in $k$ unique and incorrect k-mers**.

#### Trim reads based on Phred quality scores

Let's start the cleaning of our interleaved PE reads by trimming reads using Phred scores (33) as implemented in `seqtk`. Before executing the commands below, `cd` to the `khmer/` folder:

```{bash, eval = F}
#Trim reads based on Phred scores (default of 33)
seqtk trimfq ~/Documents/Kmers_analyses/SRA/SRR5759389_pe12.fastq > SRR5759389_pe12.trimmed.fastq
```

Using Phred scores to clean our data is not going to deal with PCR errors and potential effects of high repeated DNA sequences on the *de novo* assembly. Below, we will use information on k-mer distributions to address these issues and clean our dataset accordingly.

#### Normalize high coverage reads, remove PCR errors and low quality reads

In the next commands, `khmer` [@khmer2015] will be used to:

1. Normalize high coverage reads (>100x) based on median coverage (to optimize RAM requirements for *de novo* genome assembly).
2. Filter low abundance reads (most likely PCR errors). 
3. Final clean-up of reads to remove low quality bases, short sequences, and non-paired reads

To conduct these analyses, run the following commands in the Terminal:

```{bash, eval = F}
#1. Normalize high coverage reads (>100x) based on median reads coverage using k-mer frequencies
khmer normalize-by-median.py -p --ksize 21 -C 100 -M 1e9 -s kmer.counts -o SRR5759389_pe12.max100.trimmed.fastq SRR5759389_pe12.trimmed.fastq
```

```{bash, eval = F}
#2. Filter low abundance reads based on k-mer frequencies to minimize PCR errors
khmer filter-abund.py -V kmer.counts -o SRR5759389_pe12.max100.trimmed.norare.fastq SRR5759389_pe12.max100.trimmed.fastq
```

```{bash, eval = F}
#3. Final clean-up of reads (remove low quality bases, short sequences, and non-paired reads)
seqtk seq -q 10 -N -L 80 SRR5759389_pe12.max100.trimmed.norare.fastq | seqtk dropse > SRR5759389_pe12.max100.trimmed.norare.noshort.fastq
```

#### Prepare data for  *de novo* genome assembly

In this last section, our cleaned reads are prepared for the *de novo* genome assembly analysis conducted in `SOAPdenovo2` [@Luo2012] (done in PART 2). This is achieved by using `khmer` and renaming files using `mv` as follows:

```{bash, eval = F}
#De-interleave filtered reads (to be ready for de novo assembly in SOAPdenovo2)
khmer split-paired-reads.py SRR5759389_pe12.max100.trimmed.norare.noshort.fastq

#Rename output reads to something more human-friendly
mv SRR5759389_pe12.max100.trimmed.norare.noshort.fastq.1 SRR5759389.pe1.clean.fastq
mv SRR5759389_pe12.max100.trimmed.norare.noshort.fastq.2 SRR5759389.pe2.clean.fastq
```

#### Reads QCs on cleaned reads

Use `FastQC` to validate the reads cleaning conducted above. Please see [Step 2](#Step2) for more details on the methodology. 

### Step 4: What's "in" the reads?

Before conducting the *de novo* genome assembly (using the cleaned reads produced in [Step 3](#Step3), it is paramount to assess whether the data are contaminated and also to provide a first estimate of proportions of reads belonging to either nuclear or plastid genomes. To investigate these topics, the instructor proposes that we assess i) potential contamination by inferring reads GC contents and ii) map the clean reads against nuclear and chloroplast genome assemblies to assess proportions of reads belonging to either genomes in our library.

#### Reads GC contents

The GC content of a sequence library can provide evidence of contamination or the presence of sequence from multiple organisms (since most organisms have specific GC profiles). A GC plot inferred from a non-contaminated library would display a smooth, unimodal distribution. The existence of shoulders, or in more extreme cases a bimodal distribution, could be indicative of the presence of sequence reads from  an organism with a different GC content, which is most likely a contaminant (see Figure \@ref(fig:part1workflow)). 

Here we infer GC contents for all clean reads using the perl script `GC_content.pl`. This script requires reads to be in `fasta` format. We will then start by converting our `fastq` file into `fasta` by using `seqtk`. Data are available in the `GC_content/` folder. Please see below for the commands to be executed:

```{bash, eval = F}
#Convert fastq to fasta
seqtk seq -a ~/Documents/Kmers_analyses/khmer/	 SRR5759389_pe12.max100.trimmed.norare.noshort.fastq > SRR5759389_pe12.max100.trimmed.norare.noshort.fasta
```

**PLEASE DON'T EXECUTE THE COMMAND BELOW!** It takes few hours to calculate reads GC contents. Use the output of this command `gc_out.txt`, which is available in the `GC_content/` folder to carry on our analyses. 

```{bash, eval = F}
#Infer GC content using fasta file as input (this can take a long time)
./GC_content.pl SRR5759389_pe12.max100.trimmed.norare.noshort.fasta > gc_out.txt
```

The next command extracts the column containing the GC content per read. Since the file is very big, we use the BASH command `awk` to extract this information instead of `R`.

```{bash, eval = F}
#Extract reads GC contents (the file is big and can't be processed easily)
awk '{print$2}' gc_out.txt > gc_simple.txt
```

The last part of the analysis will be executed in `R` where we will load the data and create a histogram to look at the distribution of reads GC contents.

```{r, eval = F}
###~~~
#Infer GC content per reads
###~~~
#Load the data in R
gc_frac <- read.table('gc_simple.txt', header=T)

#Create pdf to save output of hist
pdf("GC_content_hist.pdf")
#Do the histogram of GC content 
hist(as.numeric(gc_frac[,1]), main="Histogram of GC content per reads", xlab="GC fraction")
#Close pdf file
dev.off()
```

The histogram displaying the distribution of GC values based on cleaned reads is provided in Figure \@ref(fig:GC).

```{r GC, echo=FALSE, fig.align="center", fig.cap="Histogram of GC values inferred from the cleaned library of reads (SRR5759389). See text for more details.", fig.show="asis", out.width = '80%'}
knitr::include_graphics("Images/GC_content_hist.png")
```

##### Question

> To your knowledge, based on data presented in Figure \@ref(fig:GC), is the SRR5759389 library contaminated with alien DNA?

# References